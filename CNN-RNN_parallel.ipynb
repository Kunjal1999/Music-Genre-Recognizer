{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Bidirectional, LSTM, Dropout, Activation, GRU\n",
    "from tensorflow.keras.layers import Conv2D, concatenate, MaxPooling2D, Flatten, Embedding, Lambda\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Electronic', 1: 'Experimental', 2: 'Folk', 3: 'Hip-Hop', 4: 'Instrumental', 5: 'International', 6: 'Pop', 7: 'Rock'}\n"
     ]
    }
   ],
   "source": [
    "dict_genres = {'Electronic':0, 'Experimental':1, 'Folk':2, 'Hip-Hop':3, \n",
    "               'Instrumental':4,'International':5, 'Pop' :6, 'Rock': 7  }\n",
    "\n",
    "\n",
    "reverse_map = {v: k for k, v in dict_genres.items()}\n",
    "print(reverse_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n",
      "(6394, 640, 128) (6394,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('../Music-Genre-Recognizer/Dataset/shuffled_train.npz')\n",
    "print(npzfile.files)\n",
    "X_train = npzfile['arr_0']\n",
    "y_train = npzfile['arr_1']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arr_0', 'arr_1']\n",
      "(800, 640, 128) (800,)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('../Music-Genre-Recognizer/Dataset/shuffled_valid.npz')\n",
    "print(npzfile.files)\n",
    "X_valid = npzfile['arr_0']\n",
    "y_valid = npzfile['arr_1']\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 8\n",
    "n_features = X_train.shape[2]\n",
    "n_time = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filters1=16 \n",
    "nb_filters2=32 \n",
    "nb_filters3=64\n",
    "nb_filters4=64\n",
    "nb_filters5=64\n",
    "ksize = (3,1)\n",
    "pool_size_1= (2,2) \n",
    "pool_size_2= (4,4)\n",
    "pool_size_3 = (4,2)\n",
    "\n",
    "dropout_prob = 0.20\n",
    "dense_size1 = 128\n",
    "lstm_count = 64\n",
    "num_units = 120\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCH_COUNT = 50\n",
    "L2_regularization = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_recurrent_model_build(model_input):\n",
    "    print('Building model...')\n",
    "    layer = model_input\n",
    "    \n",
    "    ### Convolutional blocks\n",
    "    conv_1 = Conv2D(filters = nb_filters1, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_1')(layer)\n",
    "    pool_1 = MaxPooling2D(pool_size_1)(conv_1)\n",
    "\n",
    "    conv_2 = Conv2D(filters = nb_filters2, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_2')(pool_1)\n",
    "    pool_2 = MaxPooling2D(pool_size_1)(conv_2)\n",
    "\n",
    "    conv_3 = Conv2D(filters = nb_filters3, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_3')(pool_2)\n",
    "    pool_3 = MaxPooling2D(pool_size_1)(conv_3)\n",
    "    \n",
    "    \n",
    "    conv_4 = Conv2D(filters = nb_filters4, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_4')(pool_3)\n",
    "    pool_4 = MaxPooling2D(pool_size_2)(conv_4)\n",
    "    \n",
    "    \n",
    "    conv_5 = Conv2D(filters = nb_filters5, kernel_size = ksize, strides=1,\n",
    "                      padding= 'valid', activation='relu', name='conv_5')(pool_4)\n",
    "    pool_5 = MaxPooling2D(pool_size_2)(conv_5)\n",
    "\n",
    "    flatten1 = Flatten()(pool_5)\n",
    "    ### Recurrent Block\n",
    "    \n",
    "    # Pooling layer\n",
    "    pool_lstm1 = MaxPooling2D(pool_size_3, name = 'pool_lstm')(layer)\n",
    "    \n",
    "    # Embedding layer\n",
    "\n",
    "    squeezed = Lambda(lambda x: K.squeeze(x, axis= -1))(pool_lstm1)\n",
    "#     flatten2 = K.squeeze(pool_lstm1, axis = -1)\n",
    "#     dense1 = Dense(dense_size1)(flatten)\n",
    "    \n",
    "    # Bidirectional GRU\n",
    "    lstm = Bidirectional(GRU(lstm_count))(squeezed)  #default merge mode is concat\n",
    "    \n",
    "    # Concat Output\n",
    "    concat = concatenate([flatten1, lstm], axis=-1, name ='concat')\n",
    "    \n",
    "    ## Softmax Output\n",
    "    output = Dense(num_classes, activation = 'softmax', name='preds')(concat)\n",
    "    \n",
    "    model_output = output\n",
    "    model = Model(model_input, model_output)\n",
    "    \n",
    "#     opt = Adam(lr=0.001)\n",
    "    opt = RMSprop(lr=0.0005)  # Optimizer\n",
    "    model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, x_val, y_val):\n",
    "    \n",
    "    n_frequency = 128\n",
    "    n_frames = 640\n",
    "    #reshape and expand dims for conv2d\n",
    "#     x_train = x_train.reshape(-1, n_frequency, n_frames)\n",
    "    x_train = np.expand_dims(x_train, axis = -1)\n",
    "    \n",
    "#     x_val = x_val.reshape(-1, n_frequency, n_frames)\n",
    "    x_val = np.expand_dims(x_val, axis = -1)\n",
    "    \n",
    "    \n",
    "    input_shape = (n_frames, n_frequency, 1)\n",
    "    model_input = Input(input_shape, name='input')\n",
    "    \n",
    "    model = conv_recurrent_model_build(model_input)\n",
    "    \n",
    "#     tb_callback = TensorBoard(log_dir='./logs/4', histogram_freq=1, batch_size=32, write_graph=True, write_grads=False,\n",
    "#                               write_images=False, embeddings_freq=0, embeddings_layer_names=None,\n",
    "#                               embeddings_metadata=None)\n",
    "    checkpoint_callback = ModelCheckpoint('./models/parallel/weights.best.h5', monitor='val_acc', verbose=1,\n",
    "                                          save_best_only=True, mode='max')\n",
    "    \n",
    "    reducelr_callback = ReduceLROnPlateau(\n",
    "                monitor='val_acc', factor=0.5, patience=10, min_delta=0.01,\n",
    "                verbose=1\n",
    "            )\n",
    "    callbacks_list = [checkpoint_callback, reducelr_callback]\n",
    "\n",
    "    # Fit the model and get training history.\n",
    "    print('Training...')\n",
    "    history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH_COUNT,\n",
    "                        validation_data=(x_val, y_val), verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary_stats(history):\n",
    "    # List all data in history\n",
    "    print(history.history.keys())\n",
    "\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tensorflow.keras.utils.to_categorical(y_train,8,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = tensorflow.keras.utils.to_categorical(y_valid,8,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6394, 8) (800, 8)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape,y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 638, 128, 16) 64          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 319, 64, 16)  0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 317, 64, 32)  1568        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 158, 32, 32)  0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 156, 32, 64)  6208        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 78, 16, 64)   0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 76, 16, 64)   12352       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 19, 4, 64)    0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 17, 4, 64)    12352       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool_lstm (MaxPooling2D)        (None, 160, 64, 1)   0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 4, 1, 64)     0           conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 160, 64)      0           pool_lstm[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128)          49536       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 384)          0           flatten_1[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "preds (Dense)                   (None, 8)            3080        concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 85,160\n",
      "Trainable params: 85,160\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Training...\n",
      "Train on 6394 samples, validate on 800 samples\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "4096/6394 [==================>...........] - ETA: 1:33 - loss: 1.9993 - acc: 0.2229"
     ]
    }
   ],
   "source": [
    "model, history  = train_model(X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bit3c13f8fff6db4497b0cd977cdce4bf32"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
